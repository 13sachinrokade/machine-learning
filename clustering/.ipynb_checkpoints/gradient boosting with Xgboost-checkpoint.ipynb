{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting XGBoost\n",
      "  Using cached https://files.pythonhosted.org/packages/5e/49/b95c037b717b4ceadc76b6e164603471225c27052d1611d5a2e832757945/xgboost-0.90-py2.py3-none-win_amd64.whl\n",
      "Requirement already satisfied: numpy in c:\\users\\student\\anaconda3\\lib\\site-packages (from XGBoost) (1.16.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\student\\anaconda3\\lib\\site-packages (from XGBoost) (1.2.1)\n",
      "Installing collected packages: XGBoost\n",
      "Successfully installed XGBoost-0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # using for plots\n",
    "import seaborn as sns #using for plots\n",
    "%matplotlib inline\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split # split train and test sets\n",
    "from sklearn.preprocessing import StandardScaler # for scaling \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Gradient Boosting Machine\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Cross Validation Score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import sys\n",
    "!{sys.executable} -m pip install XGBoost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "iris=load_iris()\n",
    "x=iris.data\n",
    "y=iris.target\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,y_train,x_test,y_test=train_test_split(x,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(x,y, test_size=0.2, \n",
    "random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "scalar = StandardScaler()\n",
    "X_train = scalar.fit_transform(X_train)\n",
    "X_validation = scalar.transform(X_validation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression::\n",
      " [[10  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  0 11]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "logis = LogisticRegression()\n",
    "logis.fit(X_train,Y_train)\n",
    "prediction=logis.predict(X_validation)\n",
    "print(\"logistic regression::\\n\",confusion_matrix(Y_validation,prediction),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM ::\n",
      " [[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X_train,Y_train)\n",
    "prediction=svm.predict(X_validation)\n",
    "print(\"SVM ::\\n\",confusion_matrix(Y_validation,prediction),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN ::\n",
      " [[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train,Y_train)\n",
    "prediction=knn.predict(X_validation)\n",
    "print(\"KNN ::\\n\",confusion_matrix(Y_validation,prediction),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree ::\n",
      " [[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dTmodel = DecisionTreeClassifier()\n",
    "dTmodel.fit(X_train,Y_train)\n",
    "prediction=dTmodel.predict(X_validation)\n",
    "print(\"DecisionTree ::\\n\",confusion_matrix(Y_validation,prediction),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest ::\n",
      " [[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rForest = RandomForestClassifier()\n",
    "rForest.fit(X_train,Y_train)\n",
    "prediction=rForest.predict(X_validation)\n",
    "print(\"RandomForest ::\\n\",confusion_matrix(Y_validation,prediction),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting ::\n",
      " [[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "grBoosting = GradientBoostingClassifier()\n",
    "grBoosting.fit(X_train,Y_train)\n",
    "prediction=grBoosting.predict(X_validation)\n",
    "print(\"GradientBoosting ::\\n\",confusion_matrix(Y_validation,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for logistic regresion: mean: 0.88 2sd: 0.15\n",
      "Scores:: [0.8        0.95833333 0.79166667 0.95833333 0.86956522]\n",
      "\n",
      "\n",
      "Accuracy for SVM: mean: 0.96 2sd: 0.09\n",
      "Scores:: [0.8        0.95833333 0.79166667 0.95833333 0.86956522]\n",
      "\n",
      "\n",
      "Accuracy for KNN: mean: 0.92 2sd: 0.12\n",
      "Scores:: [0.8        0.95833333 0.79166667 0.95833333 0.86956522]\n",
      "\n",
      "\n",
      "Accuracy for Decision Tree: mean: 0.94 2sd: 0.07\n",
      "Scores:: [0.96       0.95833333 0.875      0.95833333 0.95652174]\n",
      "\n",
      "\n",
      "Accuracy for Random Forest: mean: 0.94 2sd: 0.11\n",
      "Scores:: [0.96       0.95833333 0.83333333 1.         0.95652174]\n",
      "\n",
      "\n",
      "Accuracy for Gradient Boosting: mean: 0.94 2sd: 0.07\n",
      "Scores:: [0.96       0.95833333 0.875      0.95833333 0.95652174]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logis = LogisticRegression()\n",
    "    \n",
    "scores = cross_val_score(logis,X_train,Y_train,cv=5)\n",
    "print(\"Accuracy for logistic regresion: mean: {0:.2f} 2sd: {1:.2f}\".format(scores.mean(),scores.std() * 2))\n",
    "print(\"Scores::\",scores)\n",
    "print(\"\\n\")\n",
    "\n",
    "scores2 = cross_val_score(svm,X_train,Y_train,cv=5)\n",
    "print(\"Accuracy for SVM: mean: {0:.2f} 2sd: {1:.2f}\".format(scores2.mean(),scores2.std() * 2))\n",
    "print(\"Scores::\",scores)\n",
    "print(\"\\n\")\n",
    "\n",
    "scores3 = cross_val_score(knn,X_train,Y_train,cv=5)\n",
    "print(\"Accuracy for KNN: mean: {0:.2f} 2sd: {1:.2f}\".format(scores3.mean(),scores3.std() * 2))\n",
    "print(\"Scores::\",scores)\n",
    "print(\"\\n\")\n",
    "\n",
    "scores4 = cross_val_score(dTmodel,X_train,Y_train,cv=5)\n",
    "print(\"Accuracy for Decision Tree: mean: {0:.2f} 2sd: {1:.2f}\".format(scores4.mean(),scores4.std() * 2))\n",
    "print(\"Scores::\",scores4)\n",
    "print(\"\\n\")\n",
    "\n",
    "scores5 = cross_val_score(rForest,X_train,Y_train,cv=5)\n",
    "print(\"Accuracy for Random Forest: mean: {0:.2f} 2sd: {1:.2f}\".format(scores5.mean(),scores5.std() * 2))\n",
    "print(\"Scores::\",scores5)\n",
    "print(\"\\n\")\n",
    "\n",
    "scores6 = cross_val_score(grBoosting,X_train,Y_train,cv=5)\n",
    "print(\"Accuracy for Gradient Boosting: mean: {0:.2f} 2sd: {1:.2f}\".format(scores6.mean(),scores6.std() * 2))\n",
    "print(\"Scores::\",scores6)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.883333 (0.076376)\n",
      "LDA: 0.975000 (0.038188)\n",
      "KNN: 0.933333 (0.062361)\n",
      "CART: 0.941667 (0.065085)\n",
      "Random Forest: 0.950000 (0.066667)\n",
      "Gradient Boosting: 0.941667 (0.065085)\n",
      "NB: 0.950000 (0.055277)\n",
      "SVM: 0.950000 (0.055277)\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('Random Forest', RandomForestClassifier()))\n",
    "models.append(('Gradient Boosting', GradientBoostingClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=42)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=\"accuracy\")\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(\"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=10, random_state=42, shuffle=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'min_samples_split': 2}\n",
      "RandomForestClassifier(bootstrap=False, class_weight=None,\n",
      "            criterion='entropy', max_depth=3, max_features=2,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=None, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10,  0,  0],\n",
       "       [ 0,  9,  0],\n",
       "       [ 0,  0, 11]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "#Random Forest\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(1, 4),\n",
    "              \"min_samples_split\": sp_randint(2, 4),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 5\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, cv=5)\n",
    "\n",
    "random_search.fit(X_train, Y_train)\n",
    "print(random_search.best_params_)\n",
    "print(random_search.best_estimator_)\n",
    "confusion_matrix(Y_validation,random_search.predict(X_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 1, 'min_samples_split': 2}\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=3, max_features=1, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10,  0,  0],\n",
       "       [ 0,  8,  1],\n",
       "       [ 0,  0, 11]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 3, 4],\n",
    "              \"min_samples_split\": [2, 3, 4],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5)\n",
    "\n",
    "grid_search.fit(X_train, Y_train)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)\n",
    "confusion_matrix(Y_validation,grid_search.predict(X_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Make predictions on validation dataset\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, Y_train)\n",
    "predictions = knn.predict(X_validation)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Make predictions on validation dataset\n",
    "svn = SVC()\n",
    "svn.fit(X_train, Y_train)\n",
    "predictions = svn.predict(X_validation)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of Species: [2 2 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "X_new = numpy.array([[1, 2.1, 4, 0.2], [  4.7, 3, 1.3, 0.2 ],[  3.1, 1, 2.3, 0.3 ]])\n",
    "prediction = svn.predict(X_new)\n",
    "print(\"Prediction of Species: {}\".format(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " encode string class values as integers\n",
    "https://medium.com/@contactsunny/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621\n",
    "Note that XGBoost does not support categorical features; if your data contains categorical features, load it as a NumPy array first and then perform one-hot encoding.\n",
    "we can do either label_encode or one_hot encoding\n",
    "doubts i have:https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder_t = label_encoder.fit(Y_train)\n",
    "label_encoder_v = label_encoder.fit(Y_validation)\n",
    "label_encoded_yt = label_encoder.transform(Y_train)\n",
    "label_encoded_yv = label_encoder.transform(Y_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=label_encoded_yt)\n",
    "dtest = xgb.DMatrix(X_validation, label=label_encoded_yv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Use svmlight for less memory consumption, first dump the numpy array into svmlight format and then just pass the filename to DMatrix:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:17:52] 120x4 matrix with 480 entries loaded from dtrain.svm\n",
      "[16:17:52] 30x4 matrix with 120 entries loaded from dtest.svm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import dump_svmlight_file\n",
    "\n",
    "dump_svmlight_file(X_train, label_encoded_yt, 'dtrain.svm', zero_based=True)\n",
    "dump_svmlight_file(X_validation, label_encoded_yv, 'dtest.svm', zero_based=True)\n",
    "dtrain_svm = xgb.DMatrix('dtrain.svm')\n",
    "dtest_svm = xgb.DMatrix('dtest.svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'max_depth': 3,  # the maximum depth of each tree\n",
    "    'eta': 0.3,  # the training step for each iteration\n",
    "    'silent': 1,  # logging mode - quiet\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 3}  # the number of classes that exist in this datset\n",
    "num_round = 20  # the number of training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00563804, 0.97755206, 0.01680986],\n",
       "       [0.98254657, 0.01395846, 0.00349498],\n",
       "       [0.00363749, 0.00615226, 0.9902103 ],\n",
       "       [0.00564738, 0.97917044, 0.0151822 ],\n",
       "       [0.00540075, 0.93640935, 0.0581899 ],\n",
       "       [0.98607963, 0.0104128 , 0.00350755],\n",
       "       [0.00438964, 0.99041265, 0.0051977 ],\n",
       "       [0.0156953 , 0.06653062, 0.917774  ],\n",
       "       [0.0063378 , 0.94877166, 0.04489058],\n",
       "       [0.00438964, 0.99041265, 0.0051977 ],\n",
       "       [0.01785045, 0.07566603, 0.9064835 ],\n",
       "       [0.99054164, 0.00561866, 0.00383973],\n",
       "       [0.98254657, 0.01395846, 0.00349498],\n",
       "       [0.990855  , 0.00562044, 0.00352453],\n",
       "       [0.990855  , 0.00562044, 0.00352453],\n",
       "       [0.00435676, 0.9863815 , 0.00926175],\n",
       "       [0.0028351 , 0.00545694, 0.991708  ],\n",
       "       [0.00506935, 0.98753244, 0.00739827],\n",
       "       [0.00435527, 0.98265946, 0.01298527],\n",
       "       [0.00283684, 0.00484793, 0.9923152 ],\n",
       "       [0.990855  , 0.00562044, 0.00352453],\n",
       "       [0.01177546, 0.08546324, 0.90276134],\n",
       "       [0.990855  , 0.00562044, 0.00352453],\n",
       "       [0.00283684, 0.00484793, 0.9923152 ],\n",
       "       [0.00561747, 0.01081239, 0.98357016],\n",
       "       [0.00363441, 0.00699543, 0.9893701 ],\n",
       "       [0.00363749, 0.00615226, 0.9902103 ],\n",
       "       [0.00561747, 0.01081239, 0.98357016],\n",
       "       [0.99054164, 0.00561866, 0.00383973],\n",
       "       [0.990855  , 0.00562044, 0.00352453]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = bst.predict(dtest)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "print(precision_score(label_encoded_yv, best_preds, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bst_model.pkl']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(bst, 'bst_model.pkl', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
