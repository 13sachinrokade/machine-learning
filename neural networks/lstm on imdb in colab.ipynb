{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm on imdb.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saireddyavs/applied-ai/blob/master/neural%20networks/lstm%20on%20imdb%20in%20colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQdjqiQnKNB2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5554f9e2-fdf4-4584-ea7e-2415312c62f1"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "top_words=1000"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1xGTD4rKNCQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5dbfa6f6-c7a6-45de-a88a-dacbb0abfc0a"
      },
      "source": [
        "# got error when loading so gone for this: https://stackoverflow.com/questions/55890813/how-to-fix-object-arrays-cannot-be-loaded-when-allow-pickle-false-for-imdb-loa\n",
        "# save np.load\n",
        "np_load_old = np.load\n",
        "\n",
        "# modify the default parameters of np.load\n",
        "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
        "\n",
        "#for this step got error did the above below steps from above link\n",
        "(x_train,y_train),(x_test,y_test)=imdb.load_data(num_words=top_words)\n",
        "\n",
        "\n",
        "np.load = np_load_old"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6j_Tzo-KNCY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ee5ed39b-1cdc-4c2d-bd1a-895c6932b617"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAPdCsKFKNCo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "951e3b25-69df-4204-9865-4b6cffff5669"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clIoHVdXKNCw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8800514b-d510-463a-a694-7bda6c8bff8d"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOMNABxYKNC8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "128dea97-da1a-400b-89c1-838bec0e29e1"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqmLTA-DKNDG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "822a53d2-a6c0-4571-a52a-f98fea3a033a"
      },
      "source": [
        "print(len(x_train[0]),len(x_train[1]),len(x_train[2]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "218 189 141\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dafP18h6KNDP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a56eca25-a6a2-4b99-a08c-d36d03a04fec"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmXH8VM4KNDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# top_words not worked  do manually \n",
        "#took 1000 not got because indices[3,74] = 3078 is not in [0, 1000) eroor so taking 5000\n",
        "x_train=x_train[:5000]\n",
        "y_train=y_train[:5000]\n",
        "x_test=x_test[:5000]\n",
        "y_test=y_test[:5000]\n",
        "top_words=5000\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FvCzsX6KNDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#padding\n",
        "length=220 #taking small as i got max word length is 218 above they are actually aranged in sorted order in dataset\n",
        "from keras.preprocessing import sequence\n",
        "x_train=sequence.pad_sequences(x_train,maxlen=length)\n",
        "x_test=sequence.pad_sequences(x_test,maxlen=length)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YQaMoWTKNDv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "eef7614c-47ea-4091-b3c8-ffed88a8f2e5"
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words,32, input_length=length))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 220, 32)           160000    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdvGfR-8KND8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "5bcb8524-32f8-4db3-99eb-9b80dd4a43d6"
      },
      "source": [
        "results=model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=64)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/5\n",
            "5000/5000 [==============================] - 36s 7ms/step - loss: 0.6929 - acc: 0.5614 - val_loss: 0.6649 - val_acc: 0.6090\n",
            "Epoch 2/5\n",
            "5000/5000 [==============================] - 34s 7ms/step - loss: 0.6015 - acc: 0.7092 - val_loss: 0.4754 - val_acc: 0.7788\n",
            "Epoch 3/5\n",
            "5000/5000 [==============================] - 35s 7ms/step - loss: 0.4165 - acc: 0.8112 - val_loss: 0.4632 - val_acc: 0.7858\n",
            "Epoch 4/5\n",
            "5000/5000 [==============================] - 33s 7ms/step - loss: 0.3678 - acc: 0.8480 - val_loss: 0.4351 - val_acc: 0.8070\n",
            "Epoch 5/5\n",
            "5000/5000 [==============================] - 34s 7ms/step - loss: 0.3405 - acc: 0.8606 - val_loss: 0.4376 - val_acc: 0.8042\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFxNtH6aKNEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plt_dynamic(x, y, y_1, ax, colors=['b']):\n",
        "    ax.plot(x, y, 'b', label=\"Train Loss\")\n",
        "    ax.plot(x, y_1, 'r', label=\"Test Loss\")\n",
        "    if len(x)==1:\n",
        "        plt.legend()\n",
        "    fig.canvas.draw()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYS8uEUvKNEM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "709a1bf7-2f6c-4428-fcc3-fa1f663058bd"
      },
      "source": [
        "\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "fig,ax = plt.subplots(1,1)\n",
        "ax.set_xlabel('epoch') ; \n",
        "ax.set_ylabel('Categorical Crossentropy Loss')\n",
        "x = list(range(1,6+1))\n",
        "\n",
        "vy = results.history['val_loss']\n",
        "ty = results.history['loss']\n",
        "print(x_test.shape,len(vy),len(ty))\n",
        "#plt_dynamic(x, vy, ty, ax) #got error"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 18s 4ms/step\n",
            "Accuracy: 80.42%\n",
            "(5000, 220) 5 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ng0KS1MqgkCS1MigkSa0MCklSq/8LtY/IxFYrH18AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPFvXpumKNET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        },
        "outputId": "b9a40d58-4395-4b40-b9f5-fd0bede4a6a3"
      },
      "source": [
        "#increasing accuarcy by trainng it more times\n",
        "results=model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=20, batch_size=64)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/20\n",
            "5000/5000 [==============================] - 33s 7ms/step - loss: 0.3120 - acc: 0.8732 - val_loss: 0.4356 - val_acc: 0.8206\n",
            "Epoch 2/20\n",
            "5000/5000 [==============================] - 34s 7ms/step - loss: 0.3167 - acc: 0.8730 - val_loss: 0.4569 - val_acc: 0.8142\n",
            "Epoch 3/20\n",
            "5000/5000 [==============================] - 33s 7ms/step - loss: 0.3134 - acc: 0.8726 - val_loss: 0.4882 - val_acc: 0.7990\n",
            "Epoch 4/20\n",
            "5000/5000 [==============================] - 34s 7ms/step - loss: 0.2706 - acc: 0.8946 - val_loss: 0.4318 - val_acc: 0.8062\n",
            "Epoch 5/20\n",
            "5000/5000 [==============================] - 33s 7ms/step - loss: 0.2623 - acc: 0.8992 - val_loss: 0.4437 - val_acc: 0.8202\n",
            "Epoch 6/20\n",
            "5000/5000 [==============================] - 36s 7ms/step - loss: 0.2414 - acc: 0.9098 - val_loss: 0.4825 - val_acc: 0.8280\n",
            "Epoch 7/20\n",
            "5000/5000 [==============================] - 33s 7ms/step - loss: 0.2223 - acc: 0.9170 - val_loss: 0.4533 - val_acc: 0.8200\n",
            "Epoch 8/20\n",
            "5000/5000 [==============================] - 33s 7ms/step - loss: 0.2015 - acc: 0.9278 - val_loss: 0.4827 - val_acc: 0.8190\n",
            "Epoch 9/20\n",
            "5000/5000 [==============================] - 34s 7ms/step - loss: 0.1930 - acc: 0.9306 - val_loss: 0.5275 - val_acc: 0.8198\n",
            "Epoch 10/20\n",
            "5000/5000 [==============================] - 33s 7ms/step - loss: 0.1705 - acc: 0.9394 - val_loss: 0.5890 - val_acc: 0.8002\n",
            "Epoch 11/20\n",
            "5000/5000 [==============================] - 34s 7ms/step - loss: 0.2000 - acc: 0.9232 - val_loss: 0.5190 - val_acc: 0.8102\n",
            "Epoch 12/20\n",
            "5000/5000 [==============================] - 33s 7ms/step - loss: 0.2112 - acc: 0.9176 - val_loss: 0.5766 - val_acc: 0.7556\n",
            "Epoch 13/20\n",
            "5000/5000 [==============================] - 33s 7ms/step - loss: 0.1710 - acc: 0.9372 - val_loss: 0.5582 - val_acc: 0.8038\n",
            "Epoch 14/20\n",
            "5000/5000 [==============================] - 34s 7ms/step - loss: 0.1561 - acc: 0.9418 - val_loss: 0.5784 - val_acc: 0.7820\n",
            "Epoch 15/20\n",
            "5000/5000 [==============================] - 34s 7ms/step - loss: 0.1938 - acc: 0.9278 - val_loss: 0.6063 - val_acc: 0.8026\n",
            "Epoch 16/20\n",
            "5000/5000 [==============================] - 35s 7ms/step - loss: 0.1463 - acc: 0.9500 - val_loss: 0.6739 - val_acc: 0.7958\n",
            "Epoch 17/20\n",
            "5000/5000 [==============================] - 33s 7ms/step - loss: 0.1409 - acc: 0.9502 - val_loss: 0.6511 - val_acc: 0.7914\n",
            "Epoch 18/20\n",
            "5000/5000 [==============================] - 34s 7ms/step - loss: 0.1226 - acc: 0.9602 - val_loss: 0.7431 - val_acc: 0.7970\n",
            "Epoch 19/20\n",
            "5000/5000 [==============================] - 33s 7ms/step - loss: 0.1786 - acc: 0.9298 - val_loss: 0.6572 - val_acc: 0.7920\n",
            "Epoch 20/20\n",
            "5000/5000 [==============================] - 33s 7ms/step - loss: 0.1605 - acc: 0.9424 - val_loss: 0.7005 - val_acc: 0.8080\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYyJSIrMKNEg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a880ca4c-231e-4443-c614-fd9c259cbe85"
      },
      "source": [
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 19s 4ms/step\n",
            "Accuracy: 80.80%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxZDiQlhKNEr",
        "colab_type": "text"
      },
      "source": [
        "# using dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvOZx2bSKNEt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "1897b8d2-f2f9-47b6-cf2c-e3ac5e558c3c"
      },
      "source": [
        "from keras.layers import Dropout\n",
        "model1 = Sequential()\n",
        "model1.add(Embedding(top_words,32, input_length=length))\n",
        "model1.add(Dropout(0.2))\n",
        "model1.add(LSTM(100))\n",
        "model1.add(Dropout(0.2))\n",
        "model1.add(Dense(1, activation='sigmoid'))\n",
        "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model1.summary())\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 220, 32)           160000    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 220, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imDsH3fjKNEz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "a85a056f-4c26-4124-d8e1-ed2fc729fe14"
      },
      "source": [
        "results=model1.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=64)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/5\n",
            "5000/5000 [==============================] - 34s 7ms/step - loss: 0.6832 - acc: 0.5610 - val_loss: 0.6481 - val_acc: 0.6896\n",
            "Epoch 2/5\n",
            "5000/5000 [==============================] - 34s 7ms/step - loss: 0.5334 - acc: 0.7458 - val_loss: 0.4572 - val_acc: 0.7988\n",
            "Epoch 3/5\n",
            "5000/5000 [==============================] - 34s 7ms/step - loss: 0.3836 - acc: 0.8352 - val_loss: 0.4179 - val_acc: 0.8096\n",
            "Epoch 4/5\n",
            "5000/5000 [==============================] - 35s 7ms/step - loss: 0.3600 - acc: 0.8494 - val_loss: 0.4720 - val_acc: 0.7826\n",
            "Epoch 5/5\n",
            "5000/5000 [==============================] - 34s 7ms/step - loss: 0.3417 - acc: 0.8564 - val_loss: 0.4462 - val_acc: 0.8008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4u9yogkKNE2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "220dfa32-775a-4a15-f129-41747aee81e8"
      },
      "source": [
        "scores = model1.evaluate(x_test, y_test, verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 18s 4ms/step\n",
            "Accuracy: 80.08%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5JsF3BYKNFA",
        "colab_type": "text"
      },
      "source": [
        "#Keras provides this capability with parameters on the LSTM layer, the dropout for configuring the input dropout and recurrent_dropout for configuring the recurrent dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIaz7JZYKNFB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "00492f14-6136-49fd-d59a-29ebf06dd395"
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Embedding(top_words, 32, input_length=length))\n",
        "model2.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model2.summary())\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 220, 32)           160000    \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fIzXf66KNFH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "2f25f3ab-7224-49f3-f8de-11d2277920eb"
      },
      "source": [
        "results=model2.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=64)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/5\n",
            "5000/5000 [==============================] - 41s 8ms/step - loss: 0.6820 - acc: 0.5896 - val_loss: 0.6640 - val_acc: 0.6594\n",
            "Epoch 2/5\n",
            "5000/5000 [==============================] - 39s 8ms/step - loss: 0.5965 - acc: 0.7136 - val_loss: 0.5759 - val_acc: 0.7066\n",
            "Epoch 3/5\n",
            "5000/5000 [==============================] - 39s 8ms/step - loss: 0.4725 - acc: 0.7882 - val_loss: 0.4723 - val_acc: 0.7734\n",
            "Epoch 4/5\n",
            "5000/5000 [==============================] - 40s 8ms/step - loss: 0.4268 - acc: 0.8126 - val_loss: 0.4835 - val_acc: 0.7648\n",
            "Epoch 5/5\n",
            "5000/5000 [==============================] - 40s 8ms/step - loss: 0.3936 - acc: 0.8338 - val_loss: 0.4776 - val_acc: 0.7756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7e7pk6ZKNFQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2347adea-3353-4676-9006-897da71c0b38"
      },
      "source": [
        "scores = model2.evaluate(x_test, y_test, verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 22s 4ms/step\n",
            "Accuracy: 77.56%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNtOA52mKNFU",
        "colab_type": "text"
      },
      "source": [
        "# cnn after embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9yIUEyYKNFW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "e72edeb4-fa38-464a-d208-66ed6365df8d"
      },
      "source": [
        "from keras.layers.convolutional import Conv1D,MaxPooling1D\n",
        "model3 = Sequential()\n",
        "model3.add(Embedding(top_words, 32, input_length=length))\n",
        "model3.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "model3.add(MaxPooling1D(pool_size=2))\n",
        "model3.add(LSTM(100))\n",
        "model3.add(Dense(1, activation='sigmoid'))\n",
        "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model3.summary())\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 220, 32)           160000    \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 220, 32)           3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 110, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 216,405\n",
            "Trainable params: 216,405\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n1z8rYQKNFZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "d221adb4-a72d-4acc-d568-19c5070736d0"
      },
      "source": [
        "results=model3.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=64)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/5\n",
            "5000/5000 [==============================] - 24s 5ms/step - loss: 0.6770 - acc: 0.5536 - val_loss: 0.5828 - val_acc: 0.7028\n",
            "Epoch 2/5\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.5259 - acc: 0.7510 - val_loss: 0.4169 - val_acc: 0.8242\n",
            "Epoch 3/5\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.3434 - acc: 0.8478 - val_loss: 0.4343 - val_acc: 0.8210\n",
            "Epoch 4/5\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.3034 - acc: 0.8794 - val_loss: 0.3804 - val_acc: 0.8298\n",
            "Epoch 5/5\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.2712 - acc: 0.8884 - val_loss: 0.3834 - val_acc: 0.8296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCXsjq8PKNFe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "006ab589-cc1f-43e6-af11-21f28941c1aa"
      },
      "source": [
        "scores = model3.evaluate(x_test, y_test, verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 10s 2ms/step\n",
            "Accuracy: 82.96%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC0PIvL1KNFj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3709
        },
        "outputId": "9dfb2991-8ec2-47db-9ed4-d31607690662"
      },
      "source": [
        "results=model3.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100, batch_size=64)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.2475 - acc: 0.8990 - val_loss: 0.3820 - val_acc: 0.8342\n",
            "Epoch 2/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.2177 - acc: 0.9174 - val_loss: 0.4202 - val_acc: 0.8366\n",
            "Epoch 3/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.2058 - acc: 0.9204 - val_loss: 0.4637 - val_acc: 0.8310\n",
            "Epoch 4/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.1998 - acc: 0.9244 - val_loss: 0.4273 - val_acc: 0.8328\n",
            "Epoch 5/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.1651 - acc: 0.9388 - val_loss: 0.4418 - val_acc: 0.8228\n",
            "Epoch 6/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.1536 - acc: 0.9464 - val_loss: 0.4923 - val_acc: 0.8284\n",
            "Epoch 7/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.1301 - acc: 0.9572 - val_loss: 0.5040 - val_acc: 0.8298\n",
            "Epoch 8/100\n",
            "5000/5000 [==============================] - 19s 4ms/step - loss: 0.1251 - acc: 0.9584 - val_loss: 0.4982 - val_acc: 0.8194\n",
            "Epoch 9/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.1243 - acc: 0.9548 - val_loss: 0.6506 - val_acc: 0.8252\n",
            "Epoch 10/100\n",
            "5000/5000 [==============================] - 19s 4ms/step - loss: 0.0895 - acc: 0.9728 - val_loss: 0.6404 - val_acc: 0.8294\n",
            "Epoch 11/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.0791 - acc: 0.9752 - val_loss: 0.5768 - val_acc: 0.8236\n",
            "Epoch 12/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.1082 - acc: 0.9622 - val_loss: 0.6111 - val_acc: 0.8228\n",
            "Epoch 13/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.0636 - acc: 0.9812 - val_loss: 0.6444 - val_acc: 0.8216\n",
            "Epoch 14/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.0513 - acc: 0.9854 - val_loss: 0.5717 - val_acc: 0.8112\n",
            "Epoch 15/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.0369 - acc: 0.9920 - val_loss: 0.8093 - val_acc: 0.8234\n",
            "Epoch 16/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.0550 - acc: 0.9836 - val_loss: 0.8812 - val_acc: 0.7896\n",
            "Epoch 17/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.0563 - acc: 0.9808 - val_loss: 0.7382 - val_acc: 0.8170\n",
            "Epoch 18/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.0237 - acc: 0.9946 - val_loss: 0.8877 - val_acc: 0.8170\n",
            "Epoch 19/100\n",
            "5000/5000 [==============================] - 17s 3ms/step - loss: 0.0124 - acc: 0.9980 - val_loss: 0.9231 - val_acc: 0.8166\n",
            "Epoch 20/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.0077 - acc: 0.9990 - val_loss: 0.8833 - val_acc: 0.8162\n",
            "Epoch 21/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.0353 - acc: 0.9898 - val_loss: 0.8785 - val_acc: 0.8160\n",
            "Epoch 22/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.0180 - acc: 0.9952 - val_loss: 1.0738 - val_acc: 0.8098\n",
            "Epoch 23/100\n",
            "5000/5000 [==============================] - 17s 3ms/step - loss: 0.0518 - acc: 0.9834 - val_loss: 0.7942 - val_acc: 0.8122\n",
            "Epoch 24/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.0312 - acc: 0.9922 - val_loss: 0.8965 - val_acc: 0.8188\n",
            "Epoch 25/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.0094 - acc: 0.9986 - val_loss: 1.0464 - val_acc: 0.8206\n",
            "Epoch 26/100\n",
            "5000/5000 [==============================] - 19s 4ms/step - loss: 0.0380 - acc: 0.9878 - val_loss: 1.0508 - val_acc: 0.8140\n",
            "Epoch 27/100\n",
            "5000/5000 [==============================] - 19s 4ms/step - loss: 0.0507 - acc: 0.9802 - val_loss: 0.9051 - val_acc: 0.8142\n",
            "Epoch 28/100\n",
            "5000/5000 [==============================] - 17s 3ms/step - loss: 0.0431 - acc: 0.9860 - val_loss: 0.8848 - val_acc: 0.8168\n",
            "Epoch 29/100\n",
            "5000/5000 [==============================] - 17s 3ms/step - loss: 0.0127 - acc: 0.9978 - val_loss: 1.0161 - val_acc: 0.8172\n",
            "Epoch 30/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.0054 - acc: 0.9998 - val_loss: 1.0924 - val_acc: 0.8180\n",
            "Epoch 31/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.0063 - acc: 0.9994 - val_loss: 1.1979 - val_acc: 0.8196\n",
            "Epoch 32/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.0034 - acc: 0.9998 - val_loss: 1.2113 - val_acc: 0.8202\n",
            "Epoch 33/100\n",
            "5000/5000 [==============================] - 17s 3ms/step - loss: 0.0097 - acc: 0.9968 - val_loss: 1.1932 - val_acc: 0.8186\n",
            "Epoch 34/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.0053 - acc: 0.9994 - val_loss: 1.1758 - val_acc: 0.8206\n",
            "Epoch 35/100\n",
            "5000/5000 [==============================] - 19s 4ms/step - loss: 0.0027 - acc: 0.9998 - val_loss: 1.2821 - val_acc: 0.8184\n",
            "Epoch 36/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.0022 - acc: 0.9998 - val_loss: 1.3283 - val_acc: 0.8172\n",
            "Epoch 37/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.0019 - acc: 0.9998 - val_loss: 1.3350 - val_acc: 0.8184\n",
            "Epoch 38/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.0018 - acc: 0.9998 - val_loss: 1.3878 - val_acc: 0.8140\n",
            "Epoch 39/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.0015 - acc: 0.9998 - val_loss: 1.3280 - val_acc: 0.8166\n",
            "Epoch 40/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 0.0013 - acc: 0.9998 - val_loss: 1.4368 - val_acc: 0.8142\n",
            "Epoch 41/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 5.5404e-04 - acc: 0.9998 - val_loss: 1.4463 - val_acc: 0.8142\n",
            "Epoch 42/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 3.1306e-04 - acc: 1.0000 - val_loss: 1.4864 - val_acc: 0.8126\n",
            "Epoch 43/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 2.4781e-04 - acc: 1.0000 - val_loss: 1.5022 - val_acc: 0.8126\n",
            "Epoch 44/100\n",
            "5000/5000 [==============================] - 19s 4ms/step - loss: 2.1134e-04 - acc: 1.0000 - val_loss: 1.5414 - val_acc: 0.8114\n",
            "Epoch 45/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 1.7282e-04 - acc: 1.0000 - val_loss: 1.5785 - val_acc: 0.8120\n",
            "Epoch 46/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 1.5173e-04 - acc: 1.0000 - val_loss: 1.5792 - val_acc: 0.8124\n",
            "Epoch 47/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 1.3159e-04 - acc: 1.0000 - val_loss: 1.6239 - val_acc: 0.8122\n",
            "Epoch 48/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 1.1794e-04 - acc: 1.0000 - val_loss: 1.6337 - val_acc: 0.8122\n",
            "Epoch 49/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 1.0367e-04 - acc: 1.0000 - val_loss: 1.6648 - val_acc: 0.8116\n",
            "Epoch 50/100\n",
            "5000/5000 [==============================] - 17s 3ms/step - loss: 9.4629e-05 - acc: 1.0000 - val_loss: 1.6772 - val_acc: 0.8122\n",
            "Epoch 51/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 8.4902e-05 - acc: 1.0000 - val_loss: 1.6775 - val_acc: 0.8128\n",
            "Epoch 52/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 7.5870e-05 - acc: 1.0000 - val_loss: 1.7117 - val_acc: 0.8126\n",
            "Epoch 53/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 6.9661e-05 - acc: 1.0000 - val_loss: 1.7092 - val_acc: 0.8120\n",
            "Epoch 54/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 6.2565e-05 - acc: 1.0000 - val_loss: 1.7221 - val_acc: 0.8130\n",
            "Epoch 55/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 5.6894e-05 - acc: 1.0000 - val_loss: 1.7401 - val_acc: 0.8118\n",
            "Epoch 56/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 5.2582e-05 - acc: 1.0000 - val_loss: 1.7434 - val_acc: 0.8134\n",
            "Epoch 57/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 4.9166e-05 - acc: 1.0000 - val_loss: 1.7746 - val_acc: 0.8128\n",
            "Epoch 58/100\n",
            "5000/5000 [==============================] - 19s 4ms/step - loss: 4.5396e-05 - acc: 1.0000 - val_loss: 1.7785 - val_acc: 0.8122\n",
            "Epoch 59/100\n",
            "5000/5000 [==============================] - 19s 4ms/step - loss: 4.0932e-05 - acc: 1.0000 - val_loss: 1.7993 - val_acc: 0.8122\n",
            "Epoch 60/100\n",
            "5000/5000 [==============================] - 19s 4ms/step - loss: 3.8603e-05 - acc: 1.0000 - val_loss: 1.7936 - val_acc: 0.8132\n",
            "Epoch 61/100\n",
            "5000/5000 [==============================] - 19s 4ms/step - loss: 3.5236e-05 - acc: 1.0000 - val_loss: 1.7989 - val_acc: 0.8128\n",
            "Epoch 62/100\n",
            "5000/5000 [==============================] - 19s 4ms/step - loss: 3.3036e-05 - acc: 1.0000 - val_loss: 1.8085 - val_acc: 0.8126\n",
            "Epoch 63/100\n",
            "5000/5000 [==============================] - 17s 3ms/step - loss: 2.9880e-05 - acc: 1.0000 - val_loss: 1.8335 - val_acc: 0.8128\n",
            "Epoch 64/100\n",
            "5000/5000 [==============================] - 17s 3ms/step - loss: 2.7939e-05 - acc: 1.0000 - val_loss: 1.8621 - val_acc: 0.8124\n",
            "Epoch 65/100\n",
            "5000/5000 [==============================] - 17s 3ms/step - loss: 2.6657e-05 - acc: 1.0000 - val_loss: 1.8470 - val_acc: 0.8122\n",
            "Epoch 66/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 2.4382e-05 - acc: 1.0000 - val_loss: 1.8672 - val_acc: 0.8122\n",
            "Epoch 67/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 2.3032e-05 - acc: 1.0000 - val_loss: 1.8691 - val_acc: 0.8134\n",
            "Epoch 68/100\n",
            "5000/5000 [==============================] - 17s 3ms/step - loss: 2.1576e-05 - acc: 1.0000 - val_loss: 1.8776 - val_acc: 0.8134\n",
            "Epoch 69/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 2.0108e-05 - acc: 1.0000 - val_loss: 1.8734 - val_acc: 0.8130\n",
            "Epoch 70/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 1.9007e-05 - acc: 1.0000 - val_loss: 1.8928 - val_acc: 0.8134\n",
            "Epoch 71/100\n",
            "5000/5000 [==============================] - 19s 4ms/step - loss: 1.7312e-05 - acc: 1.0000 - val_loss: 1.9036 - val_acc: 0.8132\n",
            "Epoch 72/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 1.6414e-05 - acc: 1.0000 - val_loss: 1.9073 - val_acc: 0.8136\n",
            "Epoch 73/100\n",
            "5000/5000 [==============================] - 17s 3ms/step - loss: 1.5509e-05 - acc: 1.0000 - val_loss: 1.9226 - val_acc: 0.8132\n",
            "Epoch 74/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 1.4419e-05 - acc: 1.0000 - val_loss: 1.9355 - val_acc: 0.8130\n",
            "Epoch 75/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 1.3533e-05 - acc: 1.0000 - val_loss: 1.9431 - val_acc: 0.8132\n",
            "Epoch 76/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 1.2777e-05 - acc: 1.0000 - val_loss: 1.9493 - val_acc: 0.8138\n",
            "Epoch 77/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 1.2037e-05 - acc: 1.0000 - val_loss: 1.9589 - val_acc: 0.8136\n",
            "Epoch 78/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 1.1301e-05 - acc: 1.0000 - val_loss: 1.9495 - val_acc: 0.8134\n",
            "Epoch 79/100\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 1.0640e-05 - acc: 1.0000 - val_loss: 1.9669 - val_acc: 0.8136\n",
            "Epoch 80/100\n",
            "5000/5000 [==============================] - 20s 4ms/step - loss: 1.0206e-05 - acc: 1.0000 - val_loss: 1.9794 - val_acc: 0.8134\n",
            "Epoch 81/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 9.4548e-06 - acc: 1.0000 - val_loss: 1.9853 - val_acc: 0.8136\n",
            "Epoch 82/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 9.0949e-06 - acc: 1.0000 - val_loss: 1.9794 - val_acc: 0.8136\n",
            "Epoch 83/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 8.6026e-06 - acc: 1.0000 - val_loss: 1.9955 - val_acc: 0.8130\n",
            "Epoch 84/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 8.0761e-06 - acc: 1.0000 - val_loss: 1.9936 - val_acc: 0.8130\n",
            "Epoch 85/100\n",
            "5000/5000 [==============================] - 17s 3ms/step - loss: 7.6299e-06 - acc: 1.0000 - val_loss: 2.0142 - val_acc: 0.8140\n",
            "Epoch 86/100\n",
            "5000/5000 [==============================] - 17s 3ms/step - loss: 7.1126e-06 - acc: 1.0000 - val_loss: 2.0169 - val_acc: 0.8136\n",
            "Epoch 87/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 6.7458e-06 - acc: 1.0000 - val_loss: 2.0142 - val_acc: 0.8148\n",
            "Epoch 88/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 6.4636e-06 - acc: 1.0000 - val_loss: 2.0311 - val_acc: 0.8142\n",
            "Epoch 89/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 6.0687e-06 - acc: 1.0000 - val_loss: 2.0371 - val_acc: 0.8136\n",
            "Epoch 90/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 5.8423e-06 - acc: 1.0000 - val_loss: 2.0412 - val_acc: 0.8136\n",
            "Epoch 91/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 5.4514e-06 - acc: 1.0000 - val_loss: 2.0350 - val_acc: 0.8142\n",
            "Epoch 92/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 5.1375e-06 - acc: 1.0000 - val_loss: 2.0419 - val_acc: 0.8142\n",
            "Epoch 93/100\n",
            "5000/5000 [==============================] - 19s 4ms/step - loss: 4.9095e-06 - acc: 1.0000 - val_loss: 2.0601 - val_acc: 0.8136\n",
            "Epoch 94/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 4.5929e-06 - acc: 1.0000 - val_loss: 2.0583 - val_acc: 0.8150\n",
            "Epoch 95/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 4.3827e-06 - acc: 1.0000 - val_loss: 2.0792 - val_acc: 0.8138\n",
            "Epoch 96/100\n",
            "5000/5000 [==============================] - 19s 4ms/step - loss: 4.0884e-06 - acc: 1.0000 - val_loss: 2.0581 - val_acc: 0.8136\n",
            "Epoch 97/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 3.9838e-06 - acc: 1.0000 - val_loss: 2.0777 - val_acc: 0.8144\n",
            "Epoch 98/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 3.7140e-06 - acc: 1.0000 - val_loss: 2.0944 - val_acc: 0.8136\n",
            "Epoch 99/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 3.6061e-06 - acc: 1.0000 - val_loss: 2.1012 - val_acc: 0.8134\n",
            "Epoch 100/100\n",
            "5000/5000 [==============================] - 18s 4ms/step - loss: 3.4430e-06 - acc: 1.0000 - val_loss: 2.1043 - val_acc: 0.8134\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}